{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from ns3gym import ns3env\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import tqdm\n",
    "import subprocess\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "from agents.dqn.agent import Agent, Config\n",
    "from agents.dqn.model import QNetworkTf\n",
    "from agents.teacher import Teacher, EnvWrapper\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b773ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "scenario = \"convergence\"\n",
    "\n",
    "simTime = 60 # seconds\n",
    "stepTime = 0.01  # seconds\n",
    "history_length = 300\n",
    "\n",
    "EPISODE_COUNT = 15\n",
    "steps_per_ep = int(simTime/stepTime)\n",
    "\n",
    "sim_args = {\n",
    "    \"simTime\": simTime,\n",
    "    \"envStepTime\": stepTime,\n",
    "    \"historyLength\": history_length,\n",
    "    \"agentType\": Agent.TYPE,\n",
    "    \"scenario\": \"convergence\",\n",
    "    \"nWifi\": 2,\n",
    "}\n",
    "\n",
    "print(\"Steps per episode:\", steps_per_ep)\n",
    "\n",
    "threads_no = 1\n",
    "env = EnvWrapper(threads_no, **sim_args)\n",
    "\n",
    "#%%\n",
    "env.reset()\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "\n",
    "print(\"Observation space shape:\", ob_space)\n",
    "print(\"Action space shape:\", ac_space)\n",
    "\n",
    "assert ob_space is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01988cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "teacher = Teacher(env, 1, Preprocessor(False))\n",
    "\n",
    "lr = 4e-4\n",
    "\n",
    "agent_count = 2 # Number of agents to train\n",
    "agents = []    # List to store the agents\n",
    "\n",
    "for i in range(agent_count):\n",
    "    config = Config(buffer_size=3*steps_per_ep*threads_no, batch_size=32, gamma=0.7, tau=1e-3, lr=lr, update_every=1)\n",
    "    agent = Agent(QNetworkTf, history_length, action_size=7, config=config)\n",
    "    agent.set_epsilon(0.9, 0.001, EPISODE_COUNT-2)\n",
    "    agents.append(agent)\n",
    "\n",
    "# Test the model\n",
    "hyperparams = {**config.__dict__, **sim_args}\n",
    "tags = [\"Rew: normalized speed\",\n",
    "        \"Final\",\n",
    "        f\"{Agent.NAME}\",\n",
    "        sim_args['scenario'],\n",
    "        f\"LR: {lr}\",\n",
    "        f\"Instances: {threads_no}\",\n",
    "        f\"Station count: {sim_args['nWifi']}\",\n",
    "        *[f\"{key}: {sim_args[key]}\" for key in list(sim_args)[:3]]]\n",
    "# # agent.save()\n",
    "logger = teacher.train(agents, EPISODE_COUNT,\n",
    "                        simTime=simTime,\n",
    "                        stepTime=stepTime,\n",
    "                        history_length=history_length,\n",
    "                        send_logs=True,\n",
    "                        experimental=True,\n",
    "                        tags=tags,\n",
    "                        parameters=hyperparams)\n",
    "logger = teacher.eval(agents,\n",
    "                        simTime=simTime,\n",
    "                        stepTime=stepTime,\n",
    "                        history_length=history_length,\n",
    "                        tags=tags,\n",
    "                        parameters=hyperparams)\n",
    "# agent.save()\n",
    "\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
